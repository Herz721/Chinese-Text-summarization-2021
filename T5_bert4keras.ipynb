{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T5_bert4keras.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wQas6IFf2ubL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620864477121,"user_tz":-480,"elapsed":34980,"user":{"displayName":"Haozhe Liu","photoUrl":"","userId":"15008509609886695232"}},"outputId":"16e3ba9a-7e1c-4655-b9c5-1a8a1f5e6a5a"},"source":["# 挂载Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLMsrH_q3byG"},"source":["# 安装bert4keras rouge Google权重\n","! pip3 install bert4keras\n","! pip3 install gsutil\n","! pip3 install numpy\n","! gsutil cp -r gs://t5-data/pretrained_models/mt5/small .\n","! gsutil cp -r gs://t5-data/vocabs/mc4.250000.100extra/sentencepiece.model .\n","! pip3 install rouge\n","! pip3 install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWsHBDAm3RP9"},"source":["# 解压数据集和权重\n","! unzip /content/t5_in_bert4keras-main.zip\n","! unzip /content/nlpcc2017.zip\n","# ! unzip /content/csl_title_public.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzCn9htr27np"},"source":["# tensorflow2.x才能用GPU!!!\n","! pip3 install tensorflow==2.4.1\n","! pip3 install keras==2.3.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nJ5T0cg3Yce","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1620921135631,"user_tz":-480,"elapsed":17520169,"user":{"displayName":"Haozhe Liu","photoUrl":"","userId":"15008509609886695232"}},"outputId":"fc7a1bf8-ecbe-45be-dc64-5446c83252ab"},"source":["from __future__ import print_function\n","import os\n","os.environ['TF_KERAS'] = '1'\n","import json\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","from bert4keras.backend import keras, K\n","from bert4keras.layers import Loss\n","from bert4keras.models import build_transformer_model\n","from bert4keras.tokenizers import SpTokenizer\n","from bert4keras.optimizers import Adam\n","from bert4keras.snippets import sequence_padding, open\n","from bert4keras.snippets import DataGenerator, AutoRegressiveDecoder\n","from tensorflow.keras.models import Model\n","from rouge import Rouge\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","# 基本参数\n","max_c_len = 1024\n","max_t_len = 128\n","batch_size = 16\n","epochs = 40\n","\n","# 模型路径\n","config_path = '/content/small/t5_small.json'\n","checkpoint_path = '/content/small/model.ckpt-1000000'\n","spm_path = '/content/t5_in_bert4keras-main/tokenizer/sentencepiece_cn.model'\n","keep_tokens_path = '/content/t5_in_bert4keras-main/tokenizer/sentencepiece_cn_keep_tokens.json'\n","\n","\n","def load_data(filename):\n","    D = []\n","    with open(filename) as f:\n","        for l in f:\n","            l = json.loads(l)\n","            if 'summarization' in l: \n","              title = l['summarization']\n","            else:\n","              title = None\n","            content = l['article'].replace('<Paragraph>','\\r\\n')\n","            if len(content) > max_c_len or len(title) > max_t_len: continue\n","            D.append((title, content))\n","    return D\n","\n","\n","# 加载数据集\n","train_data = load_data('/content/train_with_summ.json')\n","valid_data = load_data('/content/evaluation_with_ground_truth.json')\n","random.shuffle(train_data)\n","train_data = train_data[:24000]\n","valid_data = valid_data[:100]\n","\n","\n","# 加载分词器\n","tokenizer = SpTokenizer(spm_path, token_start=None, token_end='</s>')\n","keep_tokens = json.load(open(keep_tokens_path))\n","\n","\n","class data_generator(DataGenerator):\n","    \"\"\"数据生成器\n","    \"\"\"\n","    def __iter__(self, random=False):\n","        batch_c_token_ids, batch_t_token_ids = [], []\n","        for is_end, (title, content) in self.sample(random):\n","            c_token_ids, _ = tokenizer.encode(content, maxlen=max_c_len)\n","            t_token_ids, _ = tokenizer.encode(title, maxlen=max_t_len)\n","            batch_c_token_ids.append(c_token_ids)\n","            batch_t_token_ids.append([0] + t_token_ids)\n","            if len(batch_c_token_ids) == self.batch_size or is_end:\n","                batch_c_token_ids = sequence_padding(batch_c_token_ids)\n","                batch_t_token_ids = sequence_padding(batch_t_token_ids)\n","                yield [batch_c_token_ids, batch_t_token_ids], None\n","                batch_c_token_ids, batch_t_token_ids = [], []\n","\n","\n","class CrossEntropy(Loss):\n","    \"\"\"交叉熵作为loss，并mask掉输入部分\n","    \"\"\"\n","    def compute_loss(self, inputs, mask=None):\n","        y_true, y_pred = inputs\n","        y_true = y_true[:, 1:]  # 目标token_ids\n","        y_mask = K.cast(mask[1], K.floatx())[:, :-1]  # 解码器自带mask\n","        y_pred = y_pred[:, :-1]  # 预测序列，错开一位\n","        loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n","        loss = K.sum(loss * y_mask) / K.sum(y_mask)\n","        return loss\n","\n","\n","t5 = build_transformer_model(\n","    config_path=config_path,\n","    checkpoint_path=checkpoint_path,\n","    keep_tokens=keep_tokens,\n","    model='t5.1.1',\n","    return_keras_model=False,\n","    name='T5',\n",")\n","\n","encoder = t5.encoder\n","decoder = t5.decoder\n","model = t5.model\n","model.summary()\n","\n","output = CrossEntropy(1)([model.inputs[1], model.outputs[0]])\n","\n","model = Model(model.inputs, output)\n","model.compile(optimizer=Adam(1e-4))\n","\n","\n","class AutoTitle(AutoRegressiveDecoder):\n","    \"\"\"seq2seq解码器\n","    \"\"\"\n","    @AutoRegressiveDecoder.wraps(default_rtype='probas')\n","    def predict(self, inputs, output_ids, states):\n","        c_encoded = inputs[0]\n","        return decoder.predict([c_encoded, output_ids])[:, -1]\n","\n","    def generate(self, text, topk=1):\n","        c_token_ids, _ = tokenizer.encode(text, maxlen=max_c_len)\n","        c_encoded = encoder.predict(np.array([c_token_ids]))[0]\n","        output_ids = self.beam_search([c_encoded], topk)  # 基于beam search\n","        return tokenizer.decode([int(i) for i in output_ids])\n","\n","\n","# 注：T5有一个很让人不解的设置，它的<bos>标记id是0，即<bos>和<pad>其实都是0\n","autotitle = AutoTitle(start_id=0, end_id=tokenizer._token_end_id, maxlen=128)\n","\n","def just_show():\n","    s1 = u'资料图：空军苏27/歼11编队，日方称约40架中国军机在23日8艘海监船驱赶日本船队期间出现在钓鱼岛附近空域日本《产经新闻》4月27日报道声称，中国8艘海监船相继进入钓鱼岛12海里执法的4月23日当天，曾有40多架中国军机出现在钓鱼岛海域周边空域，且中方军机中多半为战斗机，包括中国空军新型战机苏-27和苏-30。日本《产经新闻》声称中国军机是想通过不断的逼近，让日本航空自卫队的战机飞行员形成疲劳。日本政府高官还称：“这是前所未有的威胁。”针对日本媒体的报道，国防部官员在接受环球网采访时称，中国军队飞机在本国管辖海域上空进行正常战备巡逻，日方却颠倒黑白、倒打一耙，肆意渲染“中国威胁”。国防部官员应询表示：4月23日，日方出动多批次F-15战斗机、P3C反潜巡逻机等，对中方正常战备巡逻的飞机进行跟踪、监视和干扰，影响中方飞机正常巡逻和飞行安全。中方对此坚决采取了应对措施。中国军队飞机在本国管辖海域上空进行正常战备巡逻，日方却颠倒黑白、倒打一耙，肆意渲染“中国威胁”。国防部官员称，需要指出的是，今年年初以来，日方不断挑衅，制造事端，并采取“恶人先告状”的手法，抹黑中国军队。事实证明，日方才是地区和平稳定的麻烦制造者。我们要求日方切实采取措施，停止故意制造地区紧张局势的做法。'\n","    s2 = u'中新网5月26日电/r/n据外媒报道，世界卫生组织日前发布了一份报告，指出自杀已经取代难产，成为全球年轻女性的头号杀手。报道称，根据报告提供的数据显示，东南亚平均每10万名年龄介于15至19岁的女性死者中，就有27.92人死于自杀，男性则为21.41人；欧洲和美洲分别为6.15人及4.72人，全球平均值则是11.73人。报道指出，多年来，难产死亡一直是这个年龄层女性丧命的最主要原因，然而在过去10年，自杀取代难产死亡，成为全球年轻女性死亡的最主要原因。报告将全球分为美洲、东南亚、中东、欧洲、非洲及西太平洋6大地区，自杀唯独在非洲未有列入5大杀手之内，原因是当地难产和艾滋病死因占绝大多数。在东南亚，自杀占少女死因的比率也较其他死因高两倍。专家分析指出，造成这种结果的原因是当地性别歧视较严重。'\n","    for s in [s1, s2]:\n","        print(u'生成摘要:', autotitle.generate(s))\n","    print()\n","\n","class Evaluator(keras.callbacks.Callback):\n","    \"\"\"评估与保存\n","    \"\"\"\n","    def __init__(self):\n","        self.rouge = Rouge()\n","        self.smooth = SmoothingFunction().method1\n","        self.best_bleu = 0.\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        metrics = self.evaluate(valid_data)  # 评测模型\n","        if metrics['bleu'] > self.best_bleu:\n","            self.best_bleu = metrics['bleu']\n","            model.save_weights('./gdrive/MyDrive/T5_Bert4Keras/best_model.weights')  # 保存模型\n","        metrics['best_bleu'] = self.best_bleu\n","        print('valid_data:', metrics)\n","        just_show()\n","\n","    def evaluate(self, data, topk=1):\n","        total = 0\n","        rouge_1, rouge_2, rouge_l, bleu = 0, 0, 0, 0\n","        for title, content in tqdm(data):\n","            total += 1\n","            title = ' '.join(title).lower()\n","            pred_title = ' '.join(autotitle.generate(content, topk)).lower()\n","            if pred_title.strip():\n","                scores = self.rouge.get_scores(hyps=pred_title, refs=title)\n","                rouge_1 += scores[0]['rouge-1']['f']\n","                rouge_2 += scores[0]['rouge-2']['f']\n","                rouge_l += scores[0]['rouge-l']['f']\n","                bleu += sentence_bleu(\n","                    references=[title.split(' ')],\n","                    hypothesis=pred_title.split(' '),\n","                    smoothing_function=self.smooth\n","                )\n","        rouge_1 /= total\n","        rouge_2 /= total\n","        rouge_l /= total\n","        bleu /= total\n","        return {\n","            'rouge-1': rouge_1,\n","            'rouge-2': rouge_2,\n","            'rouge-l': rouge_l,\n","            'bleu': bleu,\n","        }\n","\n","\n","if __name__ == '__main__':\n","    model.load_weights('./gdrive/MyDrive/T5_Bert4Keras/best_model.weights')\n","    evaluator = Evaluator()\n","    train_generator = data_generator(train_data, batch_size)\n","\n","    model.fit(\n","        train_generator.forfit(),\n","        steps_per_epoch=len(train_generator),\n","        epochs=epochs,\n","        callbacks=[evaluator]\n","    )\n","\n","else:\n","    model.load_weights('./gdrive/MyDrive/T5_Bert4Keras/best_model.weights')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Encoder-Input-Token (InputLayer [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (Embedding)     (None, None, 512)    16690176    Encoder-Input-Token[0][0]        \n","__________________________________________________________________________________________________\n","Encoder-Embedding-Dropout (Drop (None, None, 512)    0           Embedding-Token[0][0]            \n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-MultiHead (None, None, 512)    512         Encoder-Embedding-Dropout[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-Embedding-Relative-Posi (None, None, 6)      192         Encoder-Embedding-Dropout[0][0]  \n","                                                                 Encoder-Embedding-Dropout[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-MultiHead (None, None, 512)    786432      Encoder-Transformer-0-MultiHeadSe\n","                                                                 Encoder-Transformer-0-MultiHeadSe\n","                                                                 Encoder-Transformer-0-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-MultiHead (None, None, 512)    0           Encoder-Transformer-0-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-MultiHead (None, None, 512)    0           Encoder-Embedding-Dropout[0][0]  \n","                                                                 Encoder-Transformer-0-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-FeedForwa (None, None, 512)    512         Encoder-Transformer-0-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-0-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-FeedForwa (None, None, 512)    0           Encoder-Transformer-0-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-0-FeedForwa (None, None, 512)    0           Encoder-Transformer-0-MultiHeadSe\n","                                                                 Encoder-Transformer-0-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-MultiHead (None, None, 512)    512         Encoder-Transformer-0-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-MultiHead (None, None, 512)    786432      Encoder-Transformer-1-MultiHeadSe\n","                                                                 Encoder-Transformer-1-MultiHeadSe\n","                                                                 Encoder-Transformer-1-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-MultiHead (None, None, 512)    0           Encoder-Transformer-1-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-MultiHead (None, None, 512)    0           Encoder-Transformer-0-FeedForward\n","                                                                 Encoder-Transformer-1-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-FeedForwa (None, None, 512)    512         Encoder-Transformer-1-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-1-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-FeedForwa (None, None, 512)    0           Encoder-Transformer-1-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-1-FeedForwa (None, None, 512)    0           Encoder-Transformer-1-MultiHeadSe\n","                                                                 Encoder-Transformer-1-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-MultiHead (None, None, 512)    512         Encoder-Transformer-1-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-MultiHead (None, None, 512)    786432      Encoder-Transformer-2-MultiHeadSe\n","                                                                 Encoder-Transformer-2-MultiHeadSe\n","                                                                 Encoder-Transformer-2-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-MultiHead (None, None, 512)    0           Encoder-Transformer-2-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-MultiHead (None, None, 512)    0           Encoder-Transformer-1-FeedForward\n","                                                                 Encoder-Transformer-2-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-FeedForwa (None, None, 512)    512         Encoder-Transformer-2-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-2-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-FeedForwa (None, None, 512)    0           Encoder-Transformer-2-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-2-FeedForwa (None, None, 512)    0           Encoder-Transformer-2-MultiHeadSe\n","                                                                 Encoder-Transformer-2-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-MultiHead (None, None, 512)    512         Encoder-Transformer-2-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-MultiHead (None, None, 512)    786432      Encoder-Transformer-3-MultiHeadSe\n","                                                                 Encoder-Transformer-3-MultiHeadSe\n","                                                                 Encoder-Transformer-3-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-MultiHead (None, None, 512)    0           Encoder-Transformer-3-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-MultiHead (None, None, 512)    0           Encoder-Transformer-2-FeedForward\n","                                                                 Encoder-Transformer-3-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-FeedForwa (None, None, 512)    512         Encoder-Transformer-3-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-3-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-FeedForwa (None, None, 512)    0           Encoder-Transformer-3-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-3-FeedForwa (None, None, 512)    0           Encoder-Transformer-3-MultiHeadSe\n","                                                                 Encoder-Transformer-3-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-MultiHead (None, None, 512)    512         Encoder-Transformer-3-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-MultiHead (None, None, 512)    786432      Encoder-Transformer-4-MultiHeadSe\n","                                                                 Encoder-Transformer-4-MultiHeadSe\n","                                                                 Encoder-Transformer-4-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-MultiHead (None, None, 512)    0           Encoder-Transformer-4-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-MultiHead (None, None, 512)    0           Encoder-Transformer-3-FeedForward\n","                                                                 Encoder-Transformer-4-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-FeedForwa (None, None, 512)    512         Encoder-Transformer-4-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-4-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-FeedForwa (None, None, 512)    0           Encoder-Transformer-4-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-4-FeedForwa (None, None, 512)    0           Encoder-Transformer-4-MultiHeadSe\n","                                                                 Encoder-Transformer-4-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-MultiHead (None, None, 512)    512         Encoder-Transformer-4-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-MultiHead (None, None, 512)    786432      Encoder-Transformer-5-MultiHeadSe\n","                                                                 Encoder-Transformer-5-MultiHeadSe\n","                                                                 Encoder-Transformer-5-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-MultiHead (None, None, 512)    0           Encoder-Transformer-5-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-MultiHead (None, None, 512)    0           Encoder-Transformer-4-FeedForward\n","                                                                 Encoder-Transformer-5-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-FeedForwa (None, None, 512)    512         Encoder-Transformer-5-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-5-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-FeedForwa (None, None, 512)    0           Encoder-Transformer-5-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-5-FeedForwa (None, None, 512)    0           Encoder-Transformer-5-MultiHeadSe\n","                                                                 Encoder-Transformer-5-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-MultiHead (None, None, 512)    512         Encoder-Transformer-5-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-MultiHead (None, None, 512)    786432      Encoder-Transformer-6-MultiHeadSe\n","                                                                 Encoder-Transformer-6-MultiHeadSe\n","                                                                 Encoder-Transformer-6-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-MultiHead (None, None, 512)    0           Encoder-Transformer-6-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-MultiHead (None, None, 512)    0           Encoder-Transformer-5-FeedForward\n","                                                                 Encoder-Transformer-6-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-FeedForwa (None, None, 512)    512         Encoder-Transformer-6-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-6-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-FeedForwa (None, None, 512)    0           Encoder-Transformer-6-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-6-FeedForwa (None, None, 512)    0           Encoder-Transformer-6-MultiHeadSe\n","                                                                 Encoder-Transformer-6-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-MultiHead (None, None, 512)    512         Encoder-Transformer-6-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-MultiHead (None, None, 512)    786432      Encoder-Transformer-7-MultiHeadSe\n","                                                                 Encoder-Transformer-7-MultiHeadSe\n","                                                                 Encoder-Transformer-7-MultiHeadSe\n","                                                                 Encoder-Embedding-Relative-Positi\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-MultiHead (None, None, 512)    0           Encoder-Transformer-7-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-MultiHead (None, None, 512)    0           Encoder-Transformer-6-FeedForward\n","                                                                 Encoder-Transformer-7-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-FeedForwa (None, None, 512)    512         Encoder-Transformer-7-MultiHeadSe\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-FeedForwa (None, None, 512)    1572864     Encoder-Transformer-7-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-FeedForwa (None, None, 512)    0           Encoder-Transformer-7-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Transformer-7-FeedForwa (None, None, 512)    0           Encoder-Transformer-7-MultiHeadSe\n","                                                                 Encoder-Transformer-7-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Output-Norm (LayerNorma (None, None, 512)    512         Encoder-Transformer-7-FeedForward\n","__________________________________________________________________________________________________\n","Encoder-Output-Dropout (Dropout (None, None, 512)    0           Encoder-Output-Norm[0][0]        \n","__________________________________________________________________________________________________\n","Decoder-Input-Token (InputLayer [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","T5_Decoder (Functional)         (None, None, 32598)  58559168    Encoder-Output-Dropout[0][0]     \n","                                                                 Decoder-Input-Token[0][0]        \n","==================================================================================================\n","Total params: 77,442,432\n","Trainable params: 77,442,432\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/40\n","1500/1500 [==============================] - 725s 455ms/step - loss: 0.3432\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/100 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 162077 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff9101d65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:55<00:00,  2.96s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.68541080629126, 'rouge-2': 0.5695124734734415, 'rouge-l': 0.6824195134568879, 'bleu': 0.5011350229574261, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40多架中国军机在钓鱼岛附近空域出现,且多半为战斗机,日方称是前所未有的威胁。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 2/40\n","1500/1500 [==============================] - 690s 460ms/step - loss: 0.2930\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:25<00:00,  2.65s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6862378115424758, 'rouge-2': 0.5667409924282985, 'rouge-l': 0.6765617203981917, 'bleu': 0.4990547190809895, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40多架中国军机越境出现在钓鱼岛附近空域,中方军机中多半为战斗机,日政府高官称这是前所未有的威胁。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 3/40\n","1500/1500 [==============================] - 685s 457ms/step - loss: 0.2692\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:25<00:00,  2.66s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6676304663559063, 'rouge-2': 0.5563272146378355, 'rouge-l': 0.6634907021123524, 'bleu': 0.48993198139572414, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40多架中国军机近日驱逐日本船队,在8艘海监船执法时,日方曾多次阻拦中方制造局势\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 4/40\n","1500/1500 [==============================] - 691s 460ms/step - loss: 0.2472\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:30<00:00,  2.71s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6762231108183369, 'rouge-2': 0.557809837220643, 'rouge-l': 0.6598332543927935, 'bleu': 0.49566214852571266, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒:40多架中国军机越境现钓鱼岛附近空域,多半为战斗机;日方妄言称中国军机是通过不断的逼近,让日本航空自卫队形成疲劳。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 5/40\n","1500/1500 [==============================] - 688s 458ms/step - loss: 0.2366\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:32<00:00,  2.72s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6769368520852624, 'rouge-2': 0.5611796025719442, 'rouge-l': 0.6671544870323376, 'bleu': 0.5000136377246764, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40余架中国军机近日驱逐日本船队,在8艘海监船执法,日方称解放军多半为战斗机\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 6/40\n","1500/1500 [==============================] - 687s 458ms/step - loss: 0.2240\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:34<00:00,  2.75s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6741885656069516, 'rouge-2': 0.5586386433751003, 'rouge-l': 0.6644178816953399, 'bleu': 0.4925532479575812, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40多架中国军机连续进入钓鱼岛海域,并曾在日军机中多半为战斗机,日政府高官称这是前所未有的威胁。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 7/40\n","1500/1500 [==============================] - 684s 456ms/step - loss: 0.2121\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:29<00:00,  2.70s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6810045393379476, 'rouge-2': 0.5656590879684911, 'rouge-l': 0.6735565952233675, 'bleu': 0.4996882336259167, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40多架中国军机连续24日登钓鱼岛海域,日方曾称中国军机通过不断逼近,让日本航空自卫队的战机飞行员形成疲劳。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 8/40\n","1500/1500 [==============================] - 682s 455ms/step - loss: 0.2045\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:24<00:00,  2.64s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6765208168838952, 'rouge-2': 0.5599279785396277, 'rouge-l': 0.6642059034194121, 'bleu': 0.49314872159843903, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒:40多架中国军机现身钓鱼岛附近空域,日方称多半为战斗机,日政府高官要求停止故意制造局势的做法。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 9/40\n","1500/1500 [==============================] - 683s 456ms/step - loss: 0.1940\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:34<00:00,  2.75s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6771880922609048, 'rouge-2': 0.5626479728223456, 'rouge-l': 0.6662759682100095, 'bleu': 0.49743612064303105, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40余架中国军机在钓鱼岛海域出现,均在中国军机中多半为战斗机,日政府高官称这是前所未有的威胁。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 10/40\n","1500/1500 [==============================] - 682s 455ms/step - loss: 0.1904\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:38<00:00,  2.79s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6808685142000331, 'rouge-2': 0.565607425404139, 'rouge-l': 0.6689767641973218, 'bleu': 0.5008512319945438, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40余架中国军机在钓鱼岛海域出现上空,在日军机上空进行正常战备巡逻,日方却颠倒黑白、倒打一耙。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 11/40\n","1500/1500 [==============================] - 687s 458ms/step - loss: 0.1828\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:39<00:00,  2.79s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6773615445355538, 'rouge-2': 0.5607213910540206, 'rouge-l': 0.664866236521425, 'bleu': 0.49322252891850177, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40余架中国军机在钓鱼岛海域出现,均在中国军机中多半为战斗机,日政府高官称这是前所未有的威胁。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 12/40\n","1500/1500 [==============================] - 685s 456ms/step - loss: 0.1771\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:35<00:00,  2.75s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6719209895284297, 'rouge-2': 0.5545854212996157, 'rouge-l': 0.6621186540179039, 'bleu': 0.490629397910775, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒称40余架中国军机连续进入钓鱼岛海域,在日军机上空进行正常战备巡逻,日方却颠倒黑白、倒打一耙。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 13/40\n","1500/1500 [==============================] - 683s 455ms/step - loss: 0.1731\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:31<00:00,  2.71s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6684248656643895, 'rouge-2': 0.5553901842501192, 'rouge-l': 0.6607701043273962, 'bleu': 0.4930350494253328, 'best_bleu': 0.5011350229574261}\n","生成摘要: 日媒:40多架中国军机连续出现钓鱼岛附近空域,日方称均颠倒黑白、倒打一耙,肆意渲染“中国威胁”。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 14/40\n","1500/1500 [==============================] - 684s 456ms/step - loss: 0.1667\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:29<00:00,  2.70s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.677581971928673, 'rouge-2': 0.5668384437518569, 'rouge-l': 0.6689220628212749, 'bleu': 0.5017966186136636, 'best_bleu': 0.5017966186136636}\n","生成摘要: 日媒称40余架中国军机在钓鱼岛海域出现,均已服役;日方称近日有多批次F-15战机,以互相逼近。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 15/40\n","1500/1500 [==============================] - 685s 457ms/step - loss: 0.1624\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:19<00:00,  2.59s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.671991489823757, 'rouge-2': 0.5591718413588314, 'rouge-l': 0.6612871381830411, 'bleu': 0.49331639470976013, 'best_bleu': 0.5017966186136636}\n","生成摘要: 日媒称40余架中国军机在钓鱼岛海域出现,中方军机多半为战斗机;日方称解放军多年前不断挑衅。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 16/40\n","1500/1500 [==============================] - 682s 454ms/step - loss: 0.1558\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:31<00:00,  2.71s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6749711166137434, 'rouge-2': 0.5604835423013238, 'rouge-l': 0.6628819719066819, 'bleu': 0.4976822809688655, 'best_bleu': 0.5017966186136636}\n","生成摘要: 日媒称40余架中国军机昨日驱逐日船执法,日方称曾多次出现在钓鱼岛海域周边空域,日方曾多次挑衅制造事端。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 17/40\n","1500/1500 [==============================] - 686s 457ms/step - loss: 0.1537\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:31<00:00,  2.72s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.6745976128812384, 'rouge-2': 0.5641596309869941, 'rouge-l': 0.6739507323499487, 'bleu': 0.49653784579138377, 'best_bleu': 0.5017966186136636}\n","生成摘要: 日媒称40架中国军机昨日驱逐日船,在8艘海监船执法,日军机多半为战斗机,日政府高官称这是前所未有的威胁。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 18/40\n","1500/1500 [==============================] - 681s 454ms/step - loss: 0.1494\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 100/100 [04:30<00:00,  2.70s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["valid_data: {'rouge-1': 0.676809436309115, 'rouge-2': 0.563547592604703, 'rouge-l': 0.6742741783340045, 'bleu': 0.4995787408418925, 'best_bleu': 0.5017966186136636}\n","生成摘要: 日媒称40余架中国军机在钓鱼岛海域出现钓鱼岛附近空域,日方称曾多次驱逐日本船队;日方称系日媒多次挑衅。\n","生成摘要: 世界卫生组织发布报告称,在过去10年,自杀取代难产死亡,成为全球年轻女性死亡的最主要原因\n","\n","Epoch 19/40\n"," 291/1500 [====>.........................] - ETA: 9:06 - loss: 0.1415"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-77394fbabc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}